{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro To Neural Networks 1.5 pg 29 - Neural Network using MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5.1 Scaling Data - we are scaling the data to a small range centered around 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.33501649, -0.04308102, ..., -1.14664746,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -1.09493684, ...,  0.54856067,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -1.09493684, ...,  1.56568555,\n",
       "         1.6951369 , -0.19600752],\n",
       "       ...,\n",
       "       [ 0.        , -0.33501649, -0.88456568, ..., -0.12952258,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649, -0.67419451, ...,  0.8876023 ,\n",
       "        -0.5056698 , -0.19600752],\n",
       "       [ 0.        , -0.33501649,  1.00877481, ...,  0.8876023 ,\n",
       "        -0.26113572, -0.19600752]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scale = StandardScaler()\n",
    "X = X_scale.fit_transform(digits.data)\n",
    "X[0:,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5.2 Creating test and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into test and train data. The test is 40% of the data and the train is 60% in this example\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = digits.target #targets are the classification in this case the numbers 0 - 9\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def convert_y_to_vect(y):\n",
    "    y_vect = np.zeros((len(y),10))\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_v_train = convert_y_to_vect(y_train)\n",
    "y_v_test = convert_y_to_vect(y_test)\n",
    "\n",
    "y_train[0], y_v_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5.4 Creating the Neural Network: 64 input nudes for the 64 pixels & 10 output layer nodes to classify & a hidden layer that usually has a number of nodes between the input and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the structure of our network [#nodes in input layer, #nodes in hidden layer, #nodes in output layer]\n",
    "nn_structure = [64, 30, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use a sigmoid activation function and its derivative\n",
    "# Sigmoid Activation Function\n",
    "def f(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivative of Sigmoid Fucntion\n",
    "def f_deriv(x):\n",
    "    return f(x) * (1-f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight Initialization (with random values)\n",
    "import numpy.random as r\n",
    "def setup_and_init_weights(nn_structure):\n",
    "    W = {}\n",
    "    b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        W[l] = r.random_sample((nn_structure[l], nn_structure[l-1]))\n",
    "        b[l] = r.random_sample((nn_structure[l],))\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to set the mean accumulation values ΔW and Δb to zero (they need to be\n",
    "the same size as the weight and bias matrices):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_tri_values(nn_structure):\n",
    "    tri_W = {}\n",
    "    tri_b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        tri_W[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        tri_b[l] = np.zeros((nn_structure[l],))\n",
    "    return tri_W, tri_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now step into the gradient descent loop, the first step is to perform a feed forward\n",
    "pass through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(x, W, b):\n",
    "    h = {1:x}\n",
    "    z = {}\n",
    "    for l in range(1, len(W)+1):\n",
    "        # if it is the first layer, then the input into the weights is x, \n",
    "        # otherwise it is the output from the last layer\n",
    "        if l == 1:\n",
    "            node_in = x\n",
    "        else:\n",
    "            node_in = h[l]\n",
    "        z[l+1] = W[l].dot(node_in) + b[l] # z^(l+1) = W^(l)*h^(l) + b^(l)\n",
    "        h[l+1] = f(z[l+1]) #h^(l) = f(z^(l))\n",
    "    return h, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to then calculate the output layer delta g(n1)\n",
    "(note its the greek symbol that looks like a g) and any hidden layer \n",
    "delta values g(l) to perform the backpropagation pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_out_layer_delta(y,h_out,z_out):\n",
    "    # delta^(nl) =  -(y_i) - h_i^(nl)) *f(z_i^(nl))\n",
    "    return -(y-h_out) * f_deriv(z_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hidden_delta(delta_plus_1, w_l,z_l):\n",
    "    # delta^(l) = (transpose(W^(l))* delta(l+1)) * f(z^(1))\n",
    "    return np.dot(np.transpose(w_l), delta_plus_1) * f_deriv(z_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(nn_structure, X,y,iter_num = 3000, alpha = 0.25):\n",
    "    W, b = setup_and_init_weights(nn_structure)\n",
    "    cnt = 0 \n",
    "    m = len(y)\n",
    "    avg_cost_func = []\n",
    "    print(\"Starting gradient descent for {} iterations\".format(iter_num))\n",
    "    while cnt < iter_num:\n",
    "        if cnt%1000 == 0:\n",
    "            print('Iteration {} of {}.'.format(cnt, iter_num))\n",
    "        tri_W, tri_b = init_tri_values(nn_structure)\n",
    "        avg_cost = 0\n",
    "        for i in range(len(y)):\n",
    "            delta = {}\n",
    "            # perform the feed forward pass and return the stored h and z values, to be used in the \n",
    "            # gradient descent step\n",
    "            h, z = feed_forward(X[i,:],W,b)\n",
    "            # loop from nl-1 to 1 backpropgating the errors\n",
    "            for l in range(len(nn_structure), 0, -1):\n",
    "                if l == len(nn_structure):\n",
    "                    delta[l] = calculate_out_layer_delta(y[i,:], h[l], z[l])\n",
    "                    avg_cost += np.linalg.norm((y[i,:]-h[l]))\n",
    "                else:\n",
    "                    if l > 1:\n",
    "                        delta[l] = calculate_hidden_delta(delta[l+1], W[l], z[l])\n",
    "                        # triW^(l)  = triW^(l) + delta^(l+1) *tranpose(h^(l))\n",
    "                    tri_W[l] += np.dot(delta[l+1][:,np.newaxis], np.transpose(h[l][:,np.newaxis]))\n",
    "                    # trib^(l) = trib^(l) + delta^(l+1)\n",
    "                    tri_b[l] += delta[l+1]\n",
    "        # perform the gradient descent step for the weights in each layer\n",
    "        for l in range(len(nn_structure)-1, 0, -1):\n",
    "            W[l] += -alpha * (1.0/m * tri_W[l])\n",
    "            b[l] += -alpha * (1.0/m * tri_b[l])\n",
    "        # complete the average cost calcuation\n",
    "        avg_cost = 1.0/m * avg_cost\n",
    "        avg_cost_func.append(avg_cost)\n",
    "        cnt += 1\n",
    "    return W, b, avg_cost_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent for 3000 iterations\n",
      "Iteration 0 of 3000.\n",
      "Iteration 1000 of 3000.\n",
      "Iteration 2000 of 3000.\n"
     ]
    }
   ],
   "source": [
    "W,b,avg_cost_func = train_nn(nn_structure, X_train, y_v_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can see the average cost function decreased as we went through\n",
    "# the gradient descent iterations of the training, slowly converging on a minimum in the\n",
    "# function:\n",
    "\n",
    "plt.plot(avg_cost_func)\n",
    "plt.ylabel(\"Average J\")\n",
    "plt.xlabel(\"Iteration number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5.5 Assessing the Accuracy of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y(W,b,X,n_layers):\n",
    "    m = X.shape[0]\n",
    "    y = np.zeros((m,))\n",
    "    for i in range(m):\n",
    "        h,z = feed_forward(X[i, :], W, b)\n",
    "        y[i] = np.argmax(h[n_layers])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can assess the accuracy of the prediction (i.e. the percentage of times the\n",
    "network predicted the handwritten digit correctly), by using the scikit learn\n",
    "accuracy_score function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.92628650904032"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = predict_y(W, b, X_test, 3)\n",
    "accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
